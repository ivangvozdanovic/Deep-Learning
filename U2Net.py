# -*- coding: utf-8 -*-
"""U2Net.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ynykhVlTDki8kKhB8P63tZvUDlKmZD8x
"""

from google.colab import drive
drive.mount('/content/drive')

import cv2 as cv
import os
from skimage import io, transform
import torch
import torchvision
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms#, utils
# import torch.optim as optim

import numpy as np
from PIL import Image
import glob

from data_loader import RescaleT
from data_loader import ToTensor
from data_loader import ToTensorLab
from data_loader import SalObjDataset

from models import U2NET # full size version 173.6 MB
from models import U2NETP # small version u2net 4.7 MB


PATH = '/content/drive/My Drive/CS 577 Project'

#%cd /content/drive/My Drive/CS 577 Project/
#%ls



# normalize the predicted SOD probability map


def normPRED(d):
    ma = torch.max(d)
    mi = torch.min(d)

    dn = (d-mi)/(ma-mi)

    return dn

def save_output(image_name,pred,d_dir):

    predict = pred
    predict = predict.squeeze()
    predict_np = predict.cpu().data.numpy()

    im = Image.fromarray(predict_np*255).convert('RGB')
    img_name = image_name.split(os.sep)[-1]
    image = io.imread(image_name)
    imo = im.resize((image.shape[1],image.shape[0]),resample=Image.BILINEAR)

    pb_np = np.array(imo)

    aaa = img_name.split(".")
    bbb = aaa[0:-1]
    imidx = bbb[0]
    for i in range(1,len(bbb)):
        imidx = imidx + "." + bbb[i]

    imo.save(d_dir+imidx+'.png')
    print("saving mask image - NOT WORKING")

def image_separation(figure_name):

    name_len = len(figure_name)
    figure_name_new = figure_name[:name_len-4]  # remove the image extension.


    mask_img_path = PATH + '/test_data/images/u2net_results/' + figure_name_new + '.png'
    og_img_path = PATH + '/test_data/images/style output/'+'stylized_'+ figure_name_new + '.jpg'

    save_out_path = PATH + '/test_data/images/final output/' + figure_name_new + '_fg.png'
    save_bckgr_path = PATH + '/test_data/images/final output/'+ figure_name_new + '_bg.png'

    predict = pred
    predict = predict.squeeze()
    predict_np = predict.cpu().data.numpy()

    im = Image.fromarray(predict_np*255).convert('RGB')
    img_name = figure_name.split(os.sep)[-1]
    image = io.imread(og_img_path)
    imo = im.resize((image.shape[1],image.shape[0]),resample=Image.BILINEAR)
    imo.save(mask_img_path)


    #mask image
    subimage=Image.open(mask_img_path)
    #original image
    original=Image.open(og_img_path)
    #background image
    bckgrimage=Image.open(og_img_path)


    subimage.convert("RGBA")
    original=original.convert("RGBA")
    bckgrimage=original.convert("RGBA")

    subdata=subimage.getdata()
    ogdata=original.getdata()
    bckdata=bckgrimage.getdata()

    newdata=[]
    newdata_bckg=[]


    for i in range(subdata.size[0]*subdata.size[1]):
      if subdata[i][0]==0 and subdata[i][1]==0 and subdata[i][2]==0:
        newdata.append((255,255,255,0))
        newdata_bckg.append(bckdata[i])
      else:
        newdata.append(ogdata[i])
        newdata_bckg.append((255,255,255,0))

    subimage.putdata(newdata)
    subimage.save(save_out_path,"PNG")


    bckgrimage.putdata(newdata_bckg)
    bckgrimage.save(save_bckgr_path,"PNG")

    return subimage, bckgrimage


def compile_result(image_name,pred):
    predict = pred
    predict = predict.squeeze()
    predict_np = predict.cpu().data.numpy()

    im = Image.fromarray(predict_np*255).convert('RGB')
    image = io.imread(image_name)
    imo = im.resize((image.shape[1],image.shape[0]),resample=Image.BILINEAR)


def main(model_name, image_dir , prediction_dir, model_dir, figure_name):
    # # --------- 1. get image path and name ---------


    img_name_list = glob.glob(image_dir + os.sep + '*')
    print(img_name_list)
    figure_path = image_dir + os.sep + figure_name
    print(figure_path)


    # --------- 2. dataloader ---------s
    #1. dataloader

    test_salobj_dataset = SalObjDataset(img_name_list = img_name_list,
                                            lbl_name_list = [],
                                            transform=transforms.Compose([RescaleT(512),
                                                                          ToTensorLab(flag=0)]) )

    # if figure_name == '':

    # else:
    #     path = image_dir + os.sep + figure_name
    #     figure_name_list = [path]
    #     print(figure_name_list)
    #     test_salobj_dataset = SalObjDataset(figure_name_list,
    #                                         lbl_name_list = [],
    #                                         transform=transforms.Compose([RescaleT(320),
    #                                                                       ToTensorLab(flag=0)]) )

    test_salobj_dataloader = DataLoader(test_salobj_dataset,
                                        batch_size=1,
                                        shuffle=False,
                                        num_workers=1)

    # --------- 3. model define ---------
    if(model_name=='u2net'):
        print("...load U2NET---173.6 MB")
        net = U2NET(3,1)
    elif(model_name=='u2netp'):
        print("...load U2NEP---4.7 MB")
        net = U2NETP(3,1)
    net.load_state_dict(torch.load(model_dir,map_location=torch.device('cpu')))
    if torch.cuda.is_available():
        net.cuda()
    net.eval()



    # --------- 4. inference for each image ---------
    for i_test, data_test in enumerate(test_salobj_dataloader):

        if img_name_list[i_test].split(os.sep)[-1] == figure_path.split(os.sep)[-1]:

            print("inferencing:",img_name_list[i_test].split(os.sep)[-1])

            inputs_test = data_test['image']
            inputs_test = inputs_test.type(torch.FloatTensor)

            if torch.cuda.is_available():
                inputs_test = Variable(inputs_test.cuda())
            else:
                inputs_test = Variable(inputs_test)

            d1,d2,d3,d4,d5,d6,d7= net(inputs_test)

            # normalization
            pred = d1[:,0,:,:]
            pred = normPRED(pred)

            #print("image type: ", type(pred))

            # save results to test_results folder
            if not os.path.exists(prediction_dir):
                os.makedirs(prediction_dir, exist_ok=True)
            save_output(img_name_list[i_test],pred,prediction_dir)\

            del d1,d2,d3,d4,d5,d6,d7

            image_separation(pred, figure_name)